{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rkWi5FXYEH48",
        "outputId": "ce209ecc-a9c8-4654-efbc-56e1ea6ed574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smolagents\n",
            "  Downloading smolagents-1.21.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.31.2 in /usr/local/lib/python3.12/dist-packages (from smolagents) (0.34.4)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from smolagents) (2.32.4)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from smolagents) (13.9.4)\n",
            "Requirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from smolagents) (3.1.6)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from smolagents) (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from smolagents) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.4->smolagents) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents) (0.1.2)\n",
            "Downloading smolagents-1.21.2-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: smolagents\n",
            "Successfully installed smolagents-1.21.2\n"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "! pip install smolagents\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/smolagents.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG0EZBjKEH4-"
      },
      "source": [
        "# Using different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvp4LIXQEH5A"
      },
      "source": [
        "`smolagents` provides a flexible framework that allows you to use various language models from different providers.\n",
        "This guide will show you how to use different model types with your agents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-sECqQSEH5C"
      },
      "source": [
        "## Available model types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqREVy51EH5D"
      },
      "source": [
        "`smolagents` supports several model types out of the box:\n",
        "1. [InferenceClientModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.InferenceClientModel): Uses Hugging Face's Inference API to access models\n",
        "2. [TransformersModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.TransformersModel): Runs models locally using the Transformers library\n",
        "3. [VLLMModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.VLLMModel): Uses vLLM for fast inference with optimized serving\n",
        "4. [MLXModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.MLXModel): Optimized for Apple Silicon devices using MLX\n",
        "5. [LiteLLMModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.LiteLLMModel): Provides access to hundreds of LLMs through LiteLLM\n",
        "6. [LiteLLMRouterModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.LiteLLMRouterModel): Distributes requests among multiple models\n",
        "7. [OpenAIServerModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.OpenAIServerModel): Provides access to any provider that implements an OpenAI-compatible API\n",
        "8. [AzureOpenAIServerModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.AzureOpenAIServerModel): Uses Azure's OpenAI service\n",
        "9. [AmazonBedrockServerModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.AmazonBedrockServerModel): Connects to AWS Bedrock's API\n",
        "\n",
        "All model classes support passing additional keyword arguments (like `temperature`, `max_tokens`, `top_p`, etc.) directly at instantiation time.\n",
        "These parameters are automatically forwarded to the underlying model's completion calls, allowing you to configure model behavior such as creativity, response length, and sampling strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8xa3jYbEH5E"
      },
      "source": [
        "## Using Google Gemini Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNHCXEoZEH5F"
      },
      "source": [
        "As explained in the Google Gemini API documentation (https://ai.google.dev/gemini-api/docs/openai),\n",
        "Google provides an OpenAI-compatible API for Gemini models, allowing you to use the [OpenAIServerModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.OpenAIServerModel)\n",
        "with Gemini models by setting the appropriate base URL.\n",
        "\n",
        "First, install the required dependencies:\n",
        "```bash\n",
        "pip install smolagents[openai]\n",
        "```\n",
        "\n",
        "Then, [get a Gemini API key](https://ai.google.dev/gemini-api/docs/api-key) and set it in your code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EtWF2UD1EH5H"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY = 'AIzaSyAE5nG3MfN80V7CPd6h9NUgpiVDFaPRBsw'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisTNCObEH5J"
      },
      "source": [
        "Now, you can initialize the Gemini model using the `OpenAIServerModel` class\n",
        "and setting the `api_base` parameter to the Gemini API base URL:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install smolagents[openai]"
      ],
      "metadata": {
        "id": "spp0uWyvEZKG",
        "outputId": "7faa2dc3-842b-4b86-e570-cb1e36ffd908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: smolagents[openai] in /usr/local/lib/python3.12/dist-packages (1.21.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.31.2 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (0.34.4)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (2.32.4)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (13.9.4)\n",
            "Requirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (3.1.6)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (1.1.1)\n",
            "Requirement already satisfied: openai>=1.58.1 in /usr/local/lib/python3.12/dist-packages (from smolagents[openai]) (1.100.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents[openai]) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.4->smolagents[openai]) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.58.1->smolagents[openai]) (1.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents[openai]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents[openai]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents[openai]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents[openai]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents[openai]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents[openai]) (2.19.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58.1->smolagents[openai]) (0.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents[openai]) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.58.1->smolagents[openai]) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DQpyrOZQEH5L"
      },
      "outputs": [],
      "source": [
        "from smolagents import OpenAIServerModel\n",
        "\n",
        "model = OpenAIServerModel(\n",
        "    model_id=\"gemini-2.0-flash\",\n",
        "    # Google Gemini OpenAI-compatible API base URL\n",
        "    api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "    api_key=GEMINI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29nNoA9EH5M"
      },
      "source": [
        "## Using OpenRouter Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCC8gGaLEH5M"
      },
      "source": [
        "OpenRouter provides access to a wide variety of language models through a unified OpenAI-compatible API.\n",
        "You can use the [OpenAIServerModel](https://huggingface.co/docs/smolagents/main/en/reference/models#smolagents.OpenAIServerModel) to connect to OpenRouter by setting the appropriate base URL.\n",
        "\n",
        "First, install the required dependencies:\n",
        "```bash\n",
        "pip install smolagents[openai]\n",
        "```\n",
        "\n",
        "Then, [get an OpenRouter API key](https://openrouter.ai/keys) and set it in your code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJF3WVf0EH5M"
      },
      "outputs": [],
      "source": [
        "OPENROUTER_API_KEY = <YOUR-OPENROUTER-API-KEY>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x68oyYbEH5N"
      },
      "source": [
        "Now, you can initialize any model available on OpenRouter using the `OpenAIServerModel` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZz1V0VYEH5O"
      },
      "outputs": [],
      "source": [
        "from smolagents import OpenAIServerModel\n",
        "\n",
        "model = OpenAIServerModel(\n",
        "    # You can use any model ID available on OpenRouter\n",
        "    model_id=\"openai/gpt-4o\",\n",
        "    # OpenRouter API base URL\n",
        "    api_base=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}